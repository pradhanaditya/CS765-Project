#!/usr/bin/env python3
import copy
import enum
import hashlib
import heapq
import json
import logging
import math
import os
import random
import sys
import time
import traceback
from collections import defaultdict
from typing import List, Dict, Union, Tuple, Set, Iterable

import coloredlogs
import gi
import joblib
import matplotlib.pyplot as plt
import networkx as nx
import numpy
from graphviz import Digraph
from threading import Lock

# Since a system can have multiple versions
# of GTK + installed, we want to make
# sure that we are importing GTK + 3.
gi.require_version("Gtk", "3.0")

# noinspection PyUnresolvedReferences
from gi.repository import Gtk, GLib

g_logger = None
gui_lock = Lock()


def defaultdict_float():
    return defaultdict(float)


class SimulatorParameters:
    """Parameters from the configuration file are stored in this class"""

    def __init__(self) -> None:
        self.output_path: str = './blockchains'
        self.simulator_data_filename: str = 'mySimulator.pkl'
        self.execution_time: float = 1000.0

        # Point 1 of Assignment-1 PDF: Total Nodes present in the P2P cryptocurrency network
        self.n_total_nodes: int = 50
        # Point 1 of Assignment-1 PDF: z% of nodes are slow
        self.z_percent_honest_slow_nodes: float = 50.0
        # Infected honest nodes percent (infected nodes are those who generate invalid transaction(s))
        self.percent_infected_nodes: float = 0.0
        # Number of individual attacker nodes
        self.number_of_individual_attacker_nodes: int = 0
        # Attacker node type: Can be either "selfish" or "stubborn" (default: selfish)
        self.attacker_node_type: str = "selfish"
        # Hash power of each attacker node
        self.individual_attacker_node_CPU_power_of_total: float = 20.0
        # Percentage of honest nodes the attacker is connected to
        self.zeta_attacker_connected_to_honest_nodes_percent: float = 50.0
        # Max delay between two blocks created, in seconds
        self.max_block_creation_delay_sec: float = 7200.0

        # Point 2 of Assignment-1 PDF: Exponential Distribution Mean for the inter-arrival
        # time between transactions generated by a peer. Randomly generated.
        self.T_tx_exp_txn_interarrival_mean_sec: float = 20.0

        # Point 7 of Assignment-1 PDF: Average time to mine a new block in the network
        self.T_k_block_avg_mining_time_sec: float = 600.0  # 600 is the mean block interarrival time for bitcoin

        self.min_light_delay_sec: float = 0.010
        self.max_light_delay_sec: float = 0.500
        self.node_initial_coins_low: float = 10.0  # used to initialize the genesis block
        self.node_initial_coins_high: float = 50.0  # used to initialize the genesis block
        self.max_transactions_per_block: int = 1000  # Point 7 of Assignment-1 PDF: max transactions a block can store
        self.mining_reward_start: float = 50.0
        self.mining_reward_update_percent: float = -50.0
        self.mining_reward_update_block_time: int = 2016
        # ---
        self.n_total_honest_nodes: int = 0
        self.number_of_slow_nodes: int = 0
        self.number_of_fast_nodes: int = 0
        self.number_of_infected_nodes: int = 0

    def load_from_file(self, config_file_name: str):
        """Initialize the simulator parameters"""
        global g_logger
        g_logger.debug(f'Loading {config_file_name=}')

        # Open the config file and parse it
        config_file = open(config_file_name)
        parameters = json.load(config_file)

        # Read parameters from the config file
        self.output_path: str = os.path.abspath(parameters['output_path'])
        self.simulator_data_filename: str = parameters['simulator_data_filename']
        os.makedirs(self.output_path, exist_ok=True)
        self.execution_time: float = parameters['execution_time']

        self.n_total_nodes: int = parameters['n_total_nodes']
        self.z_percent_honest_slow_nodes: float = parameters['z_percent_honest_slow_nodes']
        self.percent_infected_nodes: float = parameters['percent_infected_nodes']

        self.number_of_individual_attacker_nodes: int = parameters['number_of_individual_attacker_nodes']
        self.attacker_node_type: str = parameters['attacker_node_type']
        if self.attacker_node_type not in ('selfish', 'stubborn'):
            g_logger.error('Invalid "attacker_node_type" specified. Only "selfish" and "stubborn" are valid')
            g_logger.warning('Using default value of self.attacker_node_type="selfish"')
            self.attacker_node_type = 'selfish'

        self.individual_attacker_node_CPU_power_of_total: float = \
            parameters['individual_attacker_node_CPU_power_of_total']
        self.zeta_attacker_connected_to_honest_nodes_percent: float = \
            parameters['zeta_attacker_connected_to_honest_nodes_percent']

        self.max_block_creation_delay_sec: float = parameters['max_block_creation_delay_sec']

        self.T_tx_exp_txn_interarrival_mean_sec: float = parameters['T_tx_exp_txn_interarrival_mean_sec']

        self.T_k_block_avg_mining_time_sec: float = parameters['T_k_block_avg_mining_time_sec']

        self.min_light_delay_sec: float = parameters['min_light_delay_sec']
        self.max_light_delay_sec: float = parameters['max_light_delay_sec']

        self.node_initial_coins_low: float = parameters['node_initial_coins_low']
        self.node_initial_coins_high: float = parameters['node_initial_coins_high']
        self.max_transactions_per_block: int = parameters['max_transactions_per_block']

        self.mining_reward_start: float = parameters['mining_reward_start']
        self.mining_reward_update_percent: float = parameters['mining_reward_update_percent']
        self.mining_reward_update_block_time: int = parameters['mining_reward_update_block_time']

        # ---
        # number of attacker nodes in the network
        if self.number_of_individual_attacker_nodes < 0:
            g_logger.error(f'Condition not satisfied: 0 <= number_of_individual_attacker_nodes <= {self.n_total_nodes}')
            g_logger.warning('Making ZERO nodes as attacker because "number_of_individual_attacker_nodes < 0"')
            self.number_of_individual_attacker_nodes = 0
        elif self.number_of_individual_attacker_nodes > self.n_total_nodes:
            g_logger.error(f'Condition not satisfied: 0 <= number_of_individual_attacker_nodes <= {self.n_total_nodes}')
            g_logger.warning(f'Making ALL nodes as attackers because '
                             f'"number_of_individual_attacker_nodes > {self.n_total_nodes}"')
            self.number_of_individual_attacker_nodes = self.n_total_nodes

        if self.number_of_individual_attacker_nodes * self.individual_attacker_node_CPU_power_of_total > 100:
            g_logger.error(
                f'CPU power of attackers (i.e. AttackerNodes * EachAttackersPower = '
                f'{self.number_of_individual_attacker_nodes * self.individual_attacker_node_CPU_power_of_total}:.1f) % '
                f'exceed 100%'
            )
            self.number_of_individual_attacker_nodes = 100 // self.individual_attacker_node_CPU_power_of_total
            g_logger.warning(f'Making number_of_individual_attacker_nodes = {self.number_of_individual_attacker_nodes}')
            g_logger.warning(
                f'Hashing power held by attackers = '
                f'{self.number_of_individual_attacker_nodes * self.individual_attacker_node_CPU_power_of_total:.1f} %'
            )

        self.n_total_honest_nodes: int = self.n_total_nodes - self.number_of_individual_attacker_nodes

        # z% of the honest nodes are slow
        self.number_of_slow_nodes: int = int(self.n_total_honest_nodes * self.z_percent_honest_slow_nodes) // 100

        if self.number_of_slow_nodes < 0:
            g_logger.error('Condition not satisfied: 0 <= z_percent_honest_slow_nodes <= 100')
            g_logger.warning('Making ZERO nodes as slow because "z_percent_honest_slow_nodes < 0"')
            self.number_of_slow_nodes = 0
        elif self.number_of_slow_nodes > self.n_total_nodes:
            g_logger.error('Condition not satisfied: 0 <= z_percent_honest_slow_nodes <= 100')
            g_logger.warning('Making ALL nodes as slow because "z_percent_honest_slow_nodes > 100"')
            self.number_of_slow_nodes = self.n_total_nodes

        # Number of fast honest nodes
        self.number_of_fast_nodes: int = self.n_total_honest_nodes - self.number_of_slow_nodes

        # Number of infected honest nodes in the network
        #   -> Those nodes which might generate invalid transaction(s) / block(s)
        self.number_of_infected_nodes: int = int(self.n_total_honest_nodes * self.percent_infected_nodes) // 100
        if self.number_of_infected_nodes < 0:
            g_logger.error('Condition not satisfied: 0 <= percent_infected_nodes <= 100')
            g_logger.warning('Making ZERO honest nodes as infected because "percent_infected_nodes < 0"')
            self.number_of_infected_nodes = 0
        elif self.number_of_infected_nodes > self.n_total_honest_nodes:
            g_logger.error('Condition not satisfied: 0 <= percent_infected_nodes <= 100')
            g_logger.warning('Making ALL honest nodes as infected because "percent_infected_nodes > 100"')
            self.number_of_infected_nodes = self.n_total_honest_nodes

    def log_parameters(self):
        """Print all the Simulator Parameters to /dev/stdout"""
        print(f'Execution Time = {self.execution_time} seconds')
        print()
        print(f'      n  = Number of peers specified in the config file : {self.n_total_nodes}')
        print(f'      z  = {self.z_percent_honest_slow_nodes=} %')
        print(f'      z% = Number of slow nodes : {self.number_of_slow_nodes}')
        print(f'(100-z)% = Number of fast nodes : {self.number_of_fast_nodes}')
        print(f'Number of infected honest nodes : {self.number_of_infected_nodes}')
        print()
        print(f'Number of individual attacker nodes = {self.number_of_individual_attacker_nodes}')
        print(f'CPU Power of an individual attacker node of the total networks CPU power = '
              f'{self.individual_attacker_node_CPU_power_of_total}')
        print(f'Total CPU power of honest nodes = '
              f'{100 - self.number_of_individual_attacker_nodes * self.individual_attacker_node_CPU_power_of_total}')
        print(f'ζ = fraction of honest nodes an adversary is connected to = '
              f'{self.zeta_attacker_connected_to_honest_nodes_percent}')
        print()
        print(f'    T_tx = (seconds) Exponential Distribution -> '
              f'Transaction Inter-arrival Mean = {self.T_tx_exp_txn_interarrival_mean_sec}')
        print(f'          average block mining/interarrival time = {self.T_k_block_avg_mining_time_sec} seconds')
        print(f' min ρij = (seconds) min light propagation delay = {self.min_light_delay_sec}')
        print(f' max ρij = (seconds) max light propagation delay = {self.max_light_delay_sec}')
        print()
        print(f'         min initial coins = {self.node_initial_coins_low}')
        print(f'         max initial coins = {self.node_initial_coins_high}')
        print(f'max transactions per block = {self.max_transactions_per_block}')
        print(f'  max block creation delay = {self.max_block_creation_delay_sec} seconds')
        print()
        print(f'Mining reward start             = {self.mining_reward_start}')
        print(f'Mining reward update percent    = {self.mining_reward_update_percent}')
        print(f'Mining reward update block time = {self.mining_reward_update_block_time}')
        print()


class Simulator:
    def __init__(self, sp: SimulatorParameters):
        self.simulator_parameters: SimulatorParameters = sp
        self.global_time: float = 0.0
        self.nodes_list: List[Node] = list()
        self.event_queue: EventQueue = EventQueue()
        self.freeze_everything_except_network: bool = False
        pass

    def initialize(self) -> None:
        global g_logger

        # GENESIS_BLOCK = self.__create_genesis_block()
        GENESIS_BLOCK = self.__create_genesis_block_v2_empty()
        list_slow_fast: List[bool] = ([False] * self.simulator_parameters.number_of_slow_nodes) \
                                     + ([True] * self.simulator_parameters.number_of_fast_nodes)
        numpy.random.shuffle(list_slow_fast)

        list_infected: List[bool] = [
            i < self.simulator_parameters.number_of_infected_nodes
            for i in range(self.simulator_parameters.n_total_honest_nodes)
        ]
        numpy.random.shuffle(list_infected)
        list_infected_idx: List[int] = list()
        for i in range(self.simulator_parameters.n_total_honest_nodes):
            if list_infected[i]:
                list_infected_idx.append(i)
        g_logger.debug(f'{list_infected_idx=}')

        # Point 7 of PDF: Randomly generate CPU power of the nodes
        hash_power_percent: List[float] = list(numpy.random.random(self.simulator_parameters.n_total_honest_nodes))
        hash_power_percent_factor = (100 - (
                self.simulator_parameters.number_of_individual_attacker_nodes
                * self.simulator_parameters.individual_attacker_node_CPU_power_of_total
        )) / sum(hash_power_percent)
        hash_power_percent = [i * hash_power_percent_factor for i in hash_power_percent]

        g_logger.debug(f'{hash_power_percent=}')

        # Create the nodes
        self.nodes_list = [
            Node(i, self, i_hash_power, i_slow_fast, i_infected, False, GENESIS_BLOCK)
            for i, (i_hash_power, i_slow_fast, i_infected) in
            enumerate(zip(hash_power_percent, list_slow_fast, list_infected))
        ]

        # Adding individual attacker nodes to the nodes_list
        for _ in range(self.simulator_parameters.number_of_individual_attacker_nodes):
            # According to Assignment-2 problem statement PDF, attacker nodes are always fast
            self.nodes_list.append(
                Node(
                    len(self.nodes_list), self, self.simulator_parameters.individual_attacker_node_CPU_power_of_total,
                    True, False, True, GENESIS_BLOCK
                )
            )

        # Create a connected graph
        # Point 4 of Assignment-1 problem statement PDF
        g_logger.debug('Creating the network graph...')
        self.__create_connected_graph()
        g_logger.debug('Network graph created :)')

        # Begin the infinite random transaction creation process
        # While handling an old transaction, a new transaction is created
        for node in self.nodes_list:
            node.transaction_create()
            node.mining_start()
        pass

    # REFER: https://www.geeksforgeeks.org/private-methods-in-python/
    def __create_genesis_block_v1(self) -> 'Block':
        """This method shall only be called during the start of the simulation"""
        min_of_block_limit_and_nodes = min(self.simulator_parameters.n_total_nodes,
                                           self.simulator_parameters.max_transactions_per_block)

        # REFER: https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html#numpy.random.randint
        # “discrete uniform” distribution

        # Uniform random distribution to nodes
        recv_node_idx = numpy.random.randint(
            low=0,
            high=self.simulator_parameters.n_total_nodes,
            size=min_of_block_limit_and_nodes
        )

        # Uniform random distribution of money
        # In real life, these coins will be with people instead of nodes
        # TODO: change to numpy.random.uniform to generate float value for initial coins a node has
        money = numpy.random.randint(
            low=self.simulator_parameters.node_initial_coins_low,
            high=self.simulator_parameters.node_initial_coins_high + 1,
            size=min_of_block_limit_and_nodes
        )

        # Sender = -1 denotes that coins are created from thin air in the genesis block
        transactions = [Transaction(0.0, -1, recv_idx, coins) for recv_idx, coins in zip(recv_node_idx, money)]
        return Block('-1', 0.0, 0, transactions, 0.0, 0.0)

    def __create_genesis_block_v2_empty(self) -> 'Block':
        """This method shall only be called during the start of the simulation"""
        return Block('-1', 0.0, 0, list(), 0.0, 0.0)

    def __create_connected_graph(self) -> None:
        """
        Point 4 of Assignment-1 PDF: create a connected network of nodes
        NOTE: the graph is an undirected graph
        """
        # REFER: https://www.scitepress.org/Papers/2014/49373/49373.pdf
        # REFER: https://networkx.org/documentation/networkx-1.9.1/reference/generated/networkx.generators.random_graphs.barabasi_albert_graph.html
        # REFER: https://www.geeksforgeeks.org/barabasi-albert-graph-scale-free-models/
        # REFER: https://stackoverflow.com/questions/2041517/random-simple-connected-graph-generation-with-given-sparseness
        # REFER: https://stackoverflow.com/questions/6667201/how-to-define-a-two-dimensional-array

        # Total nodes in the graph
        n: int = self.simulator_parameters.n_total_nodes
        # Total honest nodes in the graph
        n_honest: int = self.simulator_parameters.n_total_honest_nodes

        # Creating the barabasi albert graph for 'n_honest' nodes, connecting
        # the honest nodes according to power law degree distribution
        # NOTE: nodes with node_id [0, n_honest-1] are honest nodes
        g: nx.classes.graph.Graph = nx.barabasi_albert_graph(
            n_honest,
            random.randint(1, 10 if n_honest > 10 else max(1, n_honest - 1))
        )

        # Point 5 of Assignment-1 PDF - latency time between sender "i" and receiver "j" for a message "m"
        #   ρ_ij is a positive minimum value corresponding to the speed of light propagation delay
        #   ρ_ij time is stored in "seconds"

        # The adjacency matrix (adj_mat) stores ρ_ij, and the matrix is NOT symmetric
        adj_mat: List[List[int]] = [[0 for i in range(n)] for j in range(n)]
        for i in range(n):
            for j in range(n):
                # Point 5 of Assignment-1 PDF
                adj_mat[i][j] = 0.010 + numpy.random.random() * (0.500 - 0.010)

        for edge in g.edges():
            node_i_id: int = edge[0]
            node_j_id: int = edge[1]

            # c_ij is the link speed between i and j
            # c_ij is in "bits per second"

            # If any of the nodes is SLOW
            c_ij = 5 * 1_000_000  # 5 Mbps

            if self.nodes_list[node_i_id].is_network_fast and self.nodes_list[node_j_id].is_network_fast:
                # If both of the nodes are FAST
                c_ij = 100 * 1_000_000  # 100 Mbps

            # Add node 'j' to the peers list of node 'i'
            self.nodes_list[node_i_id].add_new_peer(node_j_id, adj_mat[node_i_id][node_j_id], c_ij)
            # Add node 'i' to the peers list of node 'j'
            self.nodes_list[node_j_id].add_new_peer(node_i_id, adj_mat[node_j_id][node_i_id], c_ij)

        # Connecting the attacker nodes to the honest nodes
        for a_i in range(self.simulator_parameters.number_of_individual_attacker_nodes):
            # Select random honest nodes to be connected
            temp_n_neighbors = int(
                (n_honest * self.simulator_parameters.zeta_attacker_connected_to_honest_nodes_percent) / 100
            )
            temp_neighbors_list = random.sample(
                self.nodes_list[:(-self.simulator_parameters.number_of_individual_attacker_nodes)],
                temp_n_neighbors
            )
            attacker_node_id = n_honest + a_i

            # Adding the attacker node into the graph
            g.add_node(attacker_node_id)

            for temp_neighbor in temp_neighbors_list:
                temp_neighbor_id = temp_neighbor.node_id
                # c_ij = 5 Mbps (if any of the nodes is slow)
                c_ij = 5 * 1_000_000
                # NOTE: According to Assignment-2 PDF, attackers are always fast.
                #       Hence, no need to check attackers network type. However, for
                #       future updates, this check can be required.
                if self.nodes_list[temp_neighbor_id].is_network_fast \
                        and self.nodes_list[attacker_node_id].is_network_fast:
                    # c_ij = 100 Mbps (if both the nodes are fast)
                    c_ij = 100 * 1_000_000
                self.nodes_list[temp_neighbor_id].add_new_peer(attacker_node_id,
                                                               adj_mat[temp_neighbor_id][attacker_node_id], c_ij)
                self.nodes_list[attacker_node_id].add_new_peer(temp_neighbor_id,
                                                               adj_mat[attacker_node_id][temp_neighbor_id], c_ij)
                # "g" is an undirected graph
                g.add_edge(attacker_node_id, temp_neighbor_id)

        nx.draw(g, with_labels=True)
        plt.savefig(f'{self.simulator_parameters.output_path}/graph.png')
        # plt.show()

    def freeze(self) -> None:
        self.freeze_everything_except_network = True
        # self.event_queue.freeze()

    def execute_next_event(self, execute_all_same_time_events: bool = True) -> bool:
        """This will execute all events with event_completion_time==queue.top().event_completion_time"""
        global g_logger
        if self.event_queue.empty():
            g_logger.debug(f'Event queue is empty, returning...')
            return False

        event = self.event_queue.pop()
        while True:
            self.global_time = event.event_completion_time
            # NOTE: the "if" condition is used to reduce the number of redundant log operations
            if self.freeze_everything_except_network:
                if event.event_type in [EventType.EVENT_TRANSACTION_CREATE, EventType.EVENT_BLOCK_CREATE_SUCCESS]:
                    g_logger.debug(f'FREEZED: Time={self.get_global_time():.5f} , Event = {event.str_all()}')
                    if event.event_type == EventType.EVENT_BLOCK_CREATE_SUCCESS:
                        # NOTE: this is very very important
                        self.nodes_list[event.event_receiver_id].block_generation_count -= 1
                    break
                elif event.event_type not in [EventType.EVENT_TRANSACTION_CREATE, EventType.EVENT_RECV_TRANSACTION]:
                    g_logger.debug(f'Network: Time={self.get_global_time():.5f} , Event = {event.str_all()}')
            elif event.event_type not in [EventType.EVENT_TRANSACTION_CREATE, EventType.EVENT_RECV_TRANSACTION]:
                # NOTE: EventType.EVENT_RECV_TRANSACTION are not logged because they create a
                #       lot of log statements (as they are the most highly performed operations)
                #       and are of no use during debugging
                g_logger.debug(f'Time={self.get_global_time():.5f} , Event = {event.str_all()}')

            if event.event_type == EventType.EVENT_TRANSACTION_CREATE:
                txn: Transaction = event.data_obj
                self.nodes_list[event.event_receiver_id].transaction_event_handler(txn)
            elif event.event_type == EventType.EVENT_RECV_TRANSACTION:
                txn: Transaction = event.data_obj
                self.nodes_list[event.event_receiver_id].transaction_recv(txn, event.event_creator_id)
            elif event.event_type == EventType.EVENT_RECV_BLOCK:
                blk: Block = event.data_obj
                self.nodes_list[event.event_receiver_id].block_recv(blk, event.event_creator_id, self.global_time)
            elif event.event_type == EventType.EVENT_BLOCK_CREATE_SUCCESS:
                blk: Block = event.data_obj
                self.nodes_list[event.event_receiver_id].mining_complete(blk)
            else:
                g_logger.error(f'Problem: Unexpected EventType={event.event_type} , {event=}')

            if execute_all_same_time_events == False or \
                    self.event_queue.empty() or \
                    self.event_queue.top().event_completion_time > self.global_time:
                break
            event = self.event_queue.pop()
        return True

    def get_global_time(self) -> float:
        return self.global_time

    def write_all_node_tree_to_file(self):
        for node in self.nodes_list:
            self.write_node_tree_to_file(
                node_obj=node,
                file_name=f'{self.simulator_parameters.output_path}/tree_{node.node_id:03d}.txt'
            )
        pass

    def write_node_tree_to_file(self, node_obj: 'Node', file_name: str):
        global g_logger
        temp_name = file_name
        i = 0
        while os.path.exists(temp_name):
            g_logger.error(f'File already exists: "{file_name}"')
            temp_name = file_name + f'_({i:03d}).txt'
            i += 1
        with open(temp_name, 'w+') as f:
            f.write(node_obj.serialize_blockchain_to_str_v2())
            g_logger.info(f'Successfully written to file_name="{file_name}"')
        pass


class Transaction:
    def __init__(self, txn_time: float, id_sender: int, id_receiver: int, coin_amount: float):
        self.txn_time: float = txn_time
        self.id_sender: int = id_sender
        self.id_receiver: int = id_receiver
        self.coin_amount: float = coin_amount
        # Note: this is not used much in this simulator. However, it is very useful in real life
        self.txn_hash: str = self.get_hash()

    def __str__(self) -> str:
        return str([self.txn_time, self.id_sender, self.id_receiver, self.coin_amount])

    def __eq__(self, other) -> bool:
        return type(self) == type(other) and self.txn_hash == other.txn_hash

    def __hash__(self):
        return int(self.get_hash(), base=16)

    def get_hash(self) -> str:
        return hashlib.md5(str(self).encode()).hexdigest()

    @staticmethod
    def size() -> int:
        """
        Returns size in Bytes
        NOTE: Size is assumed to be 1KB (According to Assignment-1 PDF)
        """
        return 1000


class Block:
    def __init__(self, prev_block_hash: str, creation_time: float, index: int, transactions: List[Transaction],
                 recv_time: float, mine_time: float = -1.0):
        """self.index is 0-indexed"""
        self.prev_block_hash: str = prev_block_hash  # Hash of the previous block
        self.creation_time: float = creation_time  # Time when the block was created and mining started
        self.index: int = index  # This is 0-indexed, and Genesis Block is at index 0.
        self.transactions: List[Transaction] = transactions  # List of all transactions

        # The below values/variables are NOT used during hash calculation of this block
        self.curr_block_hash: str = self.get_hash()  # Hash of the current block
        self.recv_time: float = recv_time  # Time when the block was received
        self.mine_time: float = mine_time  # Time when the this block was successfully mined

    def __str__(self) -> str:
        """
        NOTE: this does not include block hash
        String of "self.prev_block_hash", "self.creation_time", "self.index" and "self.transactions"
        """
        return str([self.prev_block_hash, self.creation_time, self.index, [str(i) for i in self.transactions]])

    def __eq__(self, other) -> bool:
        if not isinstance(other, Block):
            return False
        return self.curr_block_hash == other.curr_block_hash

    def __hash__(self) -> int:
        return int(self.get_hash(), base=16)

    def str_all(self) -> str:
        return str([self.curr_block_hash, self.recv_time,  # These both are not present in __str__
                    self.prev_block_hash, self.creation_time, self.index, [str(i) for i in self.transactions]])

    def get_hash(self) -> str:
        """
        Hash is calculated based on "self.prev_block_hash", "self.creation_time", "self.index" and "self.transactions"
        """
        return hashlib.md5(str(self).encode()).hexdigest()

    def size(self) -> int:
        # REFER: https://stackoverflow.com/questions/14329794/get-size-in-bytes-needed-for-an-integer-in-python
        # In real life
        # return len(self.prev_block_hash) \
        #        + sys.getsizeof(self.creation_time) \
        #        + sys.getsizeof(self.index) \
        #        + (Transaction.size() * len(self.transactions))
        # In our simulator
        return Transaction.size() * len(self.transactions)


class Node:
    """Structure of a node on the P2P network"""

    def __init__(self, node_id: int, simulator: Simulator, hash_power_percent: float, is_network_fast: bool,
                 is_infected: bool, is_attacker: bool, GENESIS_BLOCK: Block):
        self.node_id: int = node_id
        self.simulator: Simulator = simulator
        self.is_network_fast: bool = is_network_fast
        self.is_infected: bool = is_infected
        self.is_attacker: bool = is_attacker

        # Number of successfully mined blocks (the mined block may/may not be in the longest chain)
        self.block_generation_count: int = 0
        # Dictionary of connected peers
        self.neighbors: Dict[int, Node.NodeSiblingInfo] = dict()
        # The time at which a new block with chain length > local chain length is received
        self.last_receive_time: float = -1.0
        # The time at which branch was changed from attackers Private branch to Honest miners branch
        self.last_change_branch_time: float = -1.0

        self.txn_all: Dict[str, Transaction] = dict()  # Hash -> Transaction
        self.txn_pool: List[Transaction] = list()

        self.GENESIS_BLOCK = GENESIS_BLOCK
        self.blocks_all: Dict[str, Block] = {GENESIS_BLOCK.curr_block_hash: GENESIS_BLOCK}  # Hash -> Block
        self.blocks_unvalidated: Dict[str, Tuple[int, Block]] = dict()  # Hash -> (Sender, Block)
        self.blockchain_leafs: List[str] = [GENESIS_BLOCK.curr_block_hash]  # NOTE: this is always sorted

        # The attacker maintains a private chain
        self.private_chain: List[str] = list()

        self.cache_balance: Dict[str, Dict] = defaultdict(defaultdict_float)
        self.node_hash_power_percent: float = hash_power_percent  # Range [0, 100] %
        sp: SimulatorParameters = simulator.simulator_parameters

        # Point 7 of Assignment-1 PDF: Exponential Distribution Mean for the
        # block mining time by node.
        t_meanTk = 1 / sp.T_k_block_avg_mining_time_sec
        t_lambda = hash_power_percent * t_meanTk / 100
        # TODO: Which among the below two lines is correct ?
        # self.T_k_exp_block_mining_mean = numpy.random.exponential() / t_lambda
        self.T_k_exp_block_mining_mean = 1.0 / t_lambda  # 1 * T_k_block_avg_mining_time_sec * 100 / hash_power_percent

        # This is same for all nodes
        # Point 2 of Assignment-1 PDF: Exponential Distribution Mean for inter-arrival time between transaction
        self.T_tx_exp_txn_interarrival_mean_sec = sp.T_tx_exp_txn_interarrival_mean_sec

        # This is same for all nodes
        # Max transactions a block can store
        self.max_transactions_per_block = sp.max_transactions_per_block

    def add_new_peer(self, new_peer_id: int, rho_ij: float, c_ij: int) -> bool:
        """
        Adding new peer to the neighbors list
        Inserts an edge between this and new_peer in the node graph
        """
        if new_peer_id in self.neighbors.keys():
            return False
        self.neighbors[new_peer_id] = Node.NodeSiblingInfo(new_peer_id, rho_ij, c_ij)
        return True

    def remove_peer(self, peer_id: int) -> bool:
        if peer_id not in self.neighbors.keys():
            return False
        self.neighbors.pop(peer_id)
        return True

    # REFER: https://www.geeksforgeeks.org/inner-class-in-python/
    class NodeSiblingInfo:
        def __init__(self, node_id: int, rho_ij: float, c_ij: int):
            self.node_id: int = node_id

            # Network latency parameters
            # ρ_ij = positive minimum value corresponding to speed of light propagation delay
            self.rho_ij: float = rho_ij
            # link speed between i and j in bits per second
            self.c_ij: int = c_ij

        def find_message_latency(self, message_size_bits: int) -> float:
            # Point 5 of Assignment-1 PDF
            #   - dij is the queuing delay at senders side (i.e. node i)
            #   - dij is randomly chosen from an exponential distribution with some mean `96kbits/c_ij`
            #   - NOTE: d_ij must be randomly chosen for each message transmitted from "i" to "j"
            d_ij = numpy.random.exponential(96_000 / self.c_ij)
            return self.rho_ij + (message_size_bits / self.c_ij) + d_ij

    def cache_update(self, new_tail: str) -> None:
        if new_tail in self.cache_balance.keys():
            return
        balance: Dict[int, float] = defaultdict(float)
        prev_block_hash: str = self.blocks_all[new_tail].prev_block_hash
        if prev_block_hash in self.cache_balance.keys():
            balance = self.cache_balance[prev_block_hash]
            self.cache_balance.pop(prev_block_hash)
            for txn in self.blocks_all[new_tail].transactions:
                balance[txn.id_sender] -= txn.coin_amount  # No need to handle Mining reward transaction
                balance[txn.id_receiver] += txn.coin_amount
        else:
            # self.cache_balance.clear()
            temp_tail = new_tail
            while temp_tail != self.GENESIS_BLOCK.prev_block_hash:
                for txn in self.blocks_all[temp_tail].transactions:
                    balance[txn.id_sender] -= txn.coin_amount
                    balance[txn.id_receiver] += txn.coin_amount
                if temp_tail in self.cache_balance.keys():
                    self.cache_balance.pop(temp_tail)
                temp_tail = self.blocks_all[temp_tail].prev_block_hash
        self.cache_balance[new_tail] = balance
        pass

    def change_mining_branch(self, block_tail_hash_new: str) -> None:
        global g_logger

        block_tail_hash_old = self.blockchain_leafs[-1]
        # if block_tail_hash_old == self.blocks_all[block_tail_hash_new].prev_block_hash:
        #     for txn in self.blocks_all[block_tail_hash_new].transactions:
        #         self.txn_pool.remove(txn)
        #     return

        old_idx = self.blocks_all[block_tail_hash_old].index
        new_idx = self.blocks_all[block_tail_hash_new].index
        min_idx = min(old_idx, new_idx)

        ancestor_hash_old: str = block_tail_hash_old
        ancestor_hash_new: str = block_tail_hash_new
        while min_idx < self.blocks_all[ancestor_hash_old].index:
            ancestor_hash_old = self.blocks_all[ancestor_hash_old].prev_block_hash
        while min_idx < self.blocks_all[ancestor_hash_new].index:
            ancestor_hash_new = self.blocks_all[ancestor_hash_new].prev_block_hash
        while ancestor_hash_old != ancestor_hash_new:
            ancestor_hash_old = self.blocks_all[ancestor_hash_old].prev_block_hash
            ancestor_hash_new = self.blocks_all[ancestor_hash_new].prev_block_hash
        # Now, "ancestor_hash_old" and "ancestor_hash_new" point to the common ancestor

        # Add transactions of old branch to the transaction pool
        while ancestor_hash_old != block_tail_hash_old:
            # Be careful, First txn is Mining Reward
            if self.blocks_all[block_tail_hash_old].transactions[0].id_sender == -1:
                self.txn_pool.extend(self.blocks_all[block_tail_hash_old].transactions[1:])
            else:
                self.txn_pool.extend(self.blocks_all[block_tail_hash_old].transactions)
            block_tail_hash_old = self.blocks_all[block_tail_hash_old].prev_block_hash
        # Remove included transactions from the transaction pool
        while ancestor_hash_new != block_tail_hash_new:
            for txn in self.blocks_all[block_tail_hash_new].transactions:
                if txn.id_sender == -1:
                    continue  # Mining reward transactions are never put in transaction pool
                # NOTE: there is a possibility that a transaction may not have reached me
                #       but someone must have included it in the blockchain and I must have
                #       received the block even before I see the transaction
                try:
                    self.txn_pool.remove(txn)
                except ValueError:
                    g_logger.warning(f'Block received with a transaction which is not yet received, '
                                     f'self.node_id = {self.node_id} , '
                                     f'block_hash = {block_tail_hash_new} , txn.txn_hash = {txn.txn_hash}')
            block_tail_hash_new = self.blocks_all[block_tail_hash_new].prev_block_hash
        pass

    def change_mining_to_public_branch(self) -> None:
        global g_logger

        # NOTE: only the below two line differ from "change_mining_branch"
        block_tail_hash_old = self.private_chain[-1]
        block_tail_hash_new = self.blockchain_leafs[-1]
        # if block_tail_hash_old == self.blocks_all[block_tail_hash_new].prev_block_hash:
        #     for txn in self.blocks_all[block_tail_hash_new].transactions:
        #         self.txn_pool.remove(txn)
        #     return

        old_idx = self.blocks_all[block_tail_hash_old].index
        new_idx = self.blocks_all[block_tail_hash_new].index
        min_idx = min(old_idx, new_idx)

        ancestor_hash_old: str = block_tail_hash_old
        ancestor_hash_new: str = block_tail_hash_new
        while min_idx < self.blocks_all[ancestor_hash_old].index:
            ancestor_hash_old = self.blocks_all[ancestor_hash_old].prev_block_hash
        while min_idx < self.blocks_all[ancestor_hash_new].index:
            ancestor_hash_new = self.blocks_all[ancestor_hash_new].prev_block_hash
        while ancestor_hash_old != ancestor_hash_new:
            ancestor_hash_old = self.blocks_all[ancestor_hash_old].prev_block_hash
            ancestor_hash_new = self.blocks_all[ancestor_hash_new].prev_block_hash
        # Now, "ancestor_hash_old" and "ancestor_hash_new" point to the common ancestor

        # Add transactions of old branch to the transaction pool
        while ancestor_hash_old != block_tail_hash_old:
            # Be careful, First txn is Mining Reward
            if self.blocks_all[block_tail_hash_old].transactions[0].id_sender == -1:
                self.txn_pool.extend(self.blocks_all[block_tail_hash_old].transactions[1:])
            else:
                self.txn_pool.extend(self.blocks_all[block_tail_hash_old].transactions)
            block_tail_hash_old = self.blocks_all[block_tail_hash_old].prev_block_hash
        # Remove included transactions from the transaction pool
        while ancestor_hash_new != block_tail_hash_new:
            for txn in self.blocks_all[block_tail_hash_new].transactions:
                if txn.id_sender == -1:
                    continue  # Mining reward transactions are never put in transaction pool
                # NOTE: there is a possibility that a transaction may not have reached me
                #       but someone must have included it in the blockchain and I must have
                #       received the block even before I see the transaction
                try:
                    self.txn_pool.remove(txn)
                except ValueError:
                    g_logger.warning(f'Block received with a transaction which is not yet received, '
                                     f'self.node_id = {self.node_id} , '
                                     f'block_hash = {block_tail_hash_new} , txn.txn_hash = {txn.txn_hash}')
            block_tail_hash_new = self.blocks_all[block_tail_hash_new].prev_block_hash
        pass

    def is_transaction_valid(
            self,
            transaction_obj: Transaction,
            curr_tail: Union[str, None] = None,
            senders_balance_init: float = 0.0
    ) -> bool:
        global g_logger

        if transaction_obj.txn_hash != transaction_obj.get_hash():
            return False

        if transaction_obj.coin_amount < 0.0:
            return False

        if transaction_obj.id_sender < 0:
            return False

        curr_blockchain_hash: Union[str, None] = curr_tail
        if curr_blockchain_hash is None:
            curr_blockchain_hash = self.blockchain_leafs[-1]

        senders_balance: float = senders_balance_init
        while curr_blockchain_hash != self.GENESIS_BLOCK.prev_block_hash:
            for txn in self.blocks_all[curr_blockchain_hash].transactions:
                if transaction_obj.txn_hash == txn.txn_hash:
                    # Transaction is already included in the past block
                    return False
                if transaction_obj.id_sender == txn.id_sender:
                    senders_balance -= txn.coin_amount
                elif transaction_obj.id_sender == txn.id_receiver:
                    senders_balance += txn.coin_amount
            curr_blockchain_hash = self.blocks_all[curr_blockchain_hash].prev_block_hash
        if senders_balance < 0.0:
            g_logger.error(f'-ve balance ---> node_id={self.node_id}, senders_balance = {senders_balance}, '
                           f'Blockchain tail = {self.blockchain_leafs[-1]}, transaction = {transaction_obj}')
            # TODO: do more verbose logging
        return senders_balance >= transaction_obj.coin_amount

    def get_balance(self, node_id, tail_block) -> float:
        # g_logger.debug(f'{self.blockchain_leafs=}')
        # g_logger.debug(f'{node_id=} , {tail_block=}')
        balance: float = 0.0
        while tail_block != '-1':
            for txn in self.blocks_all[tail_block].transactions:
                if node_id == txn.id_sender:
                    balance -= txn.coin_amount
                if node_id == txn.id_receiver:
                    balance += txn.coin_amount
            tail_block = self.blocks_all[tail_block].prev_block_hash
        return balance

    def transaction_create(self):
        """
        Point 2 of Assignment-1 PDF: Generate Transaction and add it to the event queue
          - Randomly Select a node for receiver
          - Coin Amount : generate randomly based on current balance
        """
        txn_receiver: int = random.choice(
            [node.node_id for node in self.simulator.nodes_list if node.node_id != self.node_id]
        )
        txn_amount: float = round(random.uniform(0, self.get_balance(self.node_id, self.blockchain_leafs[-1])), 2)
        txn_obj: Transaction = Transaction(
            self.simulator.get_global_time(),
            self.node_id,
            txn_receiver,
            txn_amount
        )

        next_txn_gen_event_delay = numpy.random.exponential(
            self.T_tx_exp_txn_interarrival_mean_sec
        )
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + next_txn_gen_event_delay,
                EventType.EVENT_TRANSACTION_CREATE,
                self.node_id,
                self.node_id,
                txn_obj
            )
        )

    def transaction_event_handler(self, txn_obj: Transaction):
        global g_logger
        if txn_obj.txn_hash in self.txn_all.keys():
            g_logger.warning(f'Problem: Transaction generated with hash same as previous txn, {txn_obj=}')
        else:
            # if self.is_transaction_valid(txn_obj):
            #     self.txn_all[txn_obj.txn_hash] = txn_obj
            #     self.txn_pool.append(txn_obj)
            # # NOTE: even invalid transactions are sent to neighbors to prove that other
            # #       peers are working properly and they will discard invalid received data
            pass
            # NOTE: txn is valid/invalid only when it is put in a block because balance
            #       of the sender can change before it is included in any block
            self.txn_all[txn_obj.txn_hash] = txn_obj
            self.txn_pool.append(txn_obj)
            for node in self.neighbors.values():
                self.transaction_send(txn_obj, node)
        self.transaction_create()

    def transaction_send(self, transaction_obj: Transaction, receiver_node: NodeSiblingInfo):
        """
            Receiver Obj : Peer Node of type NodeSiblingInfo
            it computes the latency to send the transaction
            it then generates an event in the event queue at that time.
        """
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + receiver_node.find_message_latency(8 * transaction_obj.size()),
                EventType.EVENT_RECV_TRANSACTION,
                self.node_id,
                receiver_node.node_id,
                copy.deepcopy(transaction_obj)
            )
        )

    def transaction_recv(self, transaction_obj: Transaction, senders_id: int):
        # IF I have already received the transaction; THEN I drop it
        if transaction_obj.txn_hash in self.txn_all:
            return
        # NOTE: transaction should only be validated when putting in a block
        # # IF transaction is invalid; then I drop it
        # if self.is_transaction_valid(transaction_obj) == False:
        #     return
        if transaction_obj.id_sender <= -1 or transaction_obj.coin_amount < 0:
            return
        # Store the transaction, add it to txn pool and forward it to others
        self.txn_all[transaction_obj.txn_hash] = transaction_obj
        self.txn_pool.append(transaction_obj)
        for node in self.neighbors.values():
            # Do NOT send the transaction back to the node from which it was received
            if node.node_id == senders_id:
                continue
            self.transaction_send(transaction_obj, node)
        pass

    def is_block_valid(self, block_obj: Block) -> int:
        """
        NOTE: first transaction of all blocks SHOULD ONLY be mining reward transaction
        :returns -1 to denote "False", 0 to denote "can not say", 1 to denote "True"
        """
        global g_logger

        # NOTE: Blocks with no transactions are allowed/valid
        # if len(block_obj.transactions) <= 1:
        #     return -1

        # Check if block content was modified or not
        if block_obj.get_hash() != block_obj.curr_block_hash:
            return -1

        if block_obj.prev_block_hash not in self.blocks_all:
            g_logger.warning(f'Block received whose parent is not yet received to this Node, '
                             f'time={self.simulator.get_global_time()}, '
                             f'node_id={self.node_id}, blk_hash={block_obj.curr_block_hash}')
            # g_logger.warning(f'{self.node_id=} , {block_obj.str_all()=}')
            # g_logger.debug(f'self.blocks_all.keys()   = {list(self.blocks_all.keys())}')
            # g_logger.debug(f'self.blocks_all.values() = {[i.str_all() for i in self.blocks_all.values()]}')
            # for node in self.simulator.nodes_list:
            #     if node.blocks_all[node.blockchain_leafs[-1]].index >= block_obj.index:
            #         g_logger.debug(f'\tnode.node_id = {node.node_id}')
            #         g_logger.debug(f'\tnode.blocks_all.keys()   = {[str(i) for i in node.blocks_all.keys()]}')
            #         g_logger.debug(f'\tnode.blocks_all.values() = {[i.str_all() for i in node.blocks_all.values()]}')
            return 0

        # Check creation time of the received block
        if block_obj.creation_time >= (
                self.simulator.get_global_time()
                + self.simulator.simulator_parameters.max_block_creation_delay_sec
        ):
            g_logger.warning(f'Problem: Block: Block Creation Time > currTime+max_block_creation_delay_sec')
            g_logger.debug(f'{block_obj.str_all()=}')
            return -1

        # Index of received block is invalid
        if self.blocks_all[block_obj.prev_block_hash].index + 1 != block_obj.index:
            g_logger.debug(f'Block: Invalid index block_obj={block_obj}, '
                           f'parent={self.blocks_all[block_obj.prev_block_hash]}')
            return -1

        # Miner may or may not want to take any reward
        if block_obj.transactions[0].id_sender < -1:
            g_logger.debug(f'Block: Invalid Mining Reward sender_id={block_obj.transactions[0]}')
            return -1  # Only -1 can be used for senders field in a Mining Reward transaction
        if block_obj.transactions[0].id_sender == -1:
            # Ensure mining fee is right
            c = block_obj.transactions[0].coin_amount
            sp = self.simulator.simulator_parameters
            c_expected = sp.mining_reward_start * \
                         (
                                 (1 + (sp.mining_reward_update_percent / 100)) **
                                 (block_obj.index // sp.mining_reward_update_block_time)
                         )
            # REFER: https://stackoverflow.com/questions/5595425/what-is-the-best-way-to-compare-floats-for-almost-equality-in-python
            if not math.isclose(c, c_expected):
                g_logger.warning(f'Problem: Block: Invalid transaction fee, Expected={c_expected}, Used={c}')
                return -1
        elif self.is_transaction_valid(block_obj.transactions[0]) == False:
            g_logger.debug(f'Block: Invalid First Transaction txn={block_obj.transactions[0]}')
            return -1

        self.cache_update(block_obj.prev_block_hash)

        senders_balance: Dict[int, float] = defaultdict(float)
        senders_balance[block_obj.transactions[0].id_receiver] += block_obj.transactions[0].coin_amount
        if block_obj.transactions[0].id_sender != -1:
            senders_balance[block_obj.transactions[0].id_sender] -= block_obj.transactions[0].coin_amount
        for txn in block_obj.transactions[1:]:
            if txn.id_sender == -1:
                g_logger.debug(f'Block: Only first transaction can be mining reward transaciton')
                return -1  # Only FIRST transaction can be mining reward transaction
            if txn.id_sender not in self.cache_balance[block_obj.prev_block_hash]:
                g_logger.debug(f'Cache: Something strange, {txn.id_sender}, {block_obj.prev_block_hash=}, '
                               f'{str(self.cache_balance)}, {block_obj.str_all()=}')
            senders_curr_balance: float = senders_balance[txn.id_sender] \
                                          + self.cache_balance[block_obj.prev_block_hash][txn.id_sender]

            # NOTE: we use math.isclose because of limitations of float
            # Example: if sender send 0.13 and calculated current balance is 0.129999999999999
            #          then we must allow it
            if txn.coin_amount > senders_curr_balance and (not math.isclose(txn.coin_amount, senders_curr_balance)):
                g_logger.debug(f'Block: Invalid transaction txn={txn}')
                # TODO: remove the below "if" statement as it is only for find logical bug in the simulator
                if self.is_transaction_valid(txn, block_obj.prev_block_hash, senders_balance[txn.id_sender]):
                    g_logger.debug(f'FIXME: cache is not working properly, Cache: Something strange, '
                                   f'{txn.id_sender}, {block_obj.prev_block_hash=}, {str(self.cache_balance)}, {block_obj.str_all()=}')
                    continue
                return -1
            # if not self.is_transaction_valid(txn, block_obj.prev_block_hash, senders_balance[txn.id_sender]):
            #     g_logger.debug(f'Block: Invalid transaction txn={txn}')
            #     return -1
            senders_balance[txn.id_sender] -= txn.coin_amount
            senders_balance[txn.id_receiver] += txn.coin_amount
        return 1

    def block_send(self, block_obj: Block, receiver_node: NodeSiblingInfo):
        self.simulator.event_queue.push(
            Event(
                self.simulator.get_global_time() + receiver_node.find_message_latency(8 * block_obj.size()),
                EventType.EVENT_RECV_BLOCK,
                self.node_id,
                receiver_node.node_id,
                copy.deepcopy(block_obj)
            )
        )

    def block_recv(self, block_obj: Block, senders_id: int, current_time: float):
        global g_logger

        def m_block_send_all_except(m_block_obj, m_peer_exception_id):
            for m_node in self.neighbors.values():
                # Do NOT send the block back to the node from which it was received
                if m_node.node_id == m_peer_exception_id:
                    continue
                self.block_send(m_block_obj, m_node)

        # IF I have already received the block; THEN I drop it
        if block_obj.curr_block_hash in self.blocks_all:
            return

        # set the block receive time
        block_obj.recv_time = current_time

        # TODO: decide what to do about this, I think the block should not be dropped
        # # IF block_obj.index < max value of current blockchain length; THEN I drop it
        # if block_obj.index < self.blocks_all[self.blockchain_leafs[-1]].index:
        #     return

        block_status: int = self.is_block_valid(block_obj)
        # IF block is invalid; then I drop it
        if block_status == -1:
            g_logger.warning(f'Problem: Invalid block received')
            return
        # IF parent of the block is not received; then put it in unvalidated blocks list
        if block_status == 0:
            g_logger.warning(f'Received block cannot be validated because its predecessor is not yet received, '
                             f'node_id={self.node_id}, block={block_obj}')
            self.blocks_unvalidated[block_obj.curr_block_hash] = (senders_id, block_obj,)
            return

        # Store the block and forward it to others
        self.blocks_all[block_obj.curr_block_hash] = block_obj

        # An attacker node will not forward the blocks mined by any other node
        if not self.is_attacker:
            m_block_send_all_except(block_obj, senders_id)

        # Check "self.blocks_unvalidated" and updated "block_obj"
        #   If a block whose successors already received, then "block_obj"
        #   will be updated to point to the last block in that chain
        while True:
            end_while_loop = True
            for blk_hash, (blk_sender_id, blk_obj) in self.blocks_unvalidated.items():
                if block_obj.curr_block_hash != blk_obj.prev_block_hash:
                    continue
                # We have already received a successor of the received node
                if self.is_block_valid(blk_obj) == 1:
                    # block is valid
                    end_while_loop = False
                    block_obj = blk_obj
                    self.blocks_all[blk_hash] = blk_obj
                    if not self.is_attacker:
                        m_block_send_all_except(blk_obj, blk_sender_id)
                    g_logger.info(f'node_id={self.node_id}, '
                                  f'Successfully processed an unvalidated block block={blk_obj}')
                    self.blocks_unvalidated.pop(blk_hash)
                else:
                    # block is invalid, pop all blocks which have this block as the ancestor
                    end_while_loop = True
                    successors_1: Set[str] = {blk_hash}
                    successors_2: Set[str] = set()
                    while len(successors_1) != 0:
                        for i in successors_1:
                            successors_2.union(set(filter(
                                lambda x: self.blocks_all[x].prev_block_hash == i,
                                self.blocks_unvalidated
                            )))
                        for i in successors_1:
                            self.blocks_unvalidated.pop(i)
                        successors_1 = successors_2
                        successors_2 = set()
                    pass
                break
            if end_while_loop:
                break

        # Difference between the length of the private chain and the public chain
        deltaPrivatePublic = 0
        block_obj_extends_current_chain = block_obj.index > self.blocks_all[self.blockchain_leafs[-1]].index
        if len(self.private_chain) > 0:
            deltaPrivatePublic = self.blocks_all[self.private_chain[-1]].index - \
                                 self.blocks_all[self.blockchain_leafs[-1]].index

        to_start_new_mining = False
        if block_obj.index > self.blocks_all[self.blockchain_leafs[-1]].index:
            to_start_new_mining = True
            self.last_receive_time = current_time
            g_logger.info(f'{self.node_id=}, Changing mining branch, '
                          f'new={block_obj.curr_block_hash}, current={self.blockchain_leafs[-1]}')
            # Attacker will continue mining privately until the honest chain wins
            if not self.is_attacker:
                self.change_mining_branch(block_obj.curr_block_hash)
            # TODO: verify if this is to be executed by both attacker and honest nodes or not
            # Insert the block_obj into self.blockchain_leafs
            self.blockchain_leafs.append(block_obj.curr_block_hash)
            if not self.is_attacker:
                self.cache_update(block_obj.curr_block_hash)
            # This is very IMPORTANT
            if len(self.private_chain) > 0:
                deltaPrivatePublic = self.blocks_all[self.private_chain[-1]].index - \
                                     (self.blocks_all[self.blockchain_leafs[-1]].index - 1)

        if self.is_attacker and block_obj_extends_current_chain:
            to_start_new_mining = False
            # If the honest public chain takes the lead, the attacker will start mining on the new public chain
            if deltaPrivatePublic <= 0:  # After receiving the block, there is transition from lead of 0 to 0 or -ve
                if len(self.private_chain) > 0:
                    self.change_mining_to_public_branch()
                    self.cache_update(block_obj.curr_block_hash)
                    self.private_chain.clear()
                self.last_change_branch_time = self.simulator.get_global_time()
                to_start_new_mining = True
            elif deltaPrivatePublic == 1:  # After receiving the block, there is transition from lead of 1 to 0
                # TODO: we have to broadcast all privately mined blocks till "last_block_private_chain_hash"
                # Both the public and the private chain are of equal length, so the attacker node will try out it's luck
                last_block_private_chain_hash = self.private_chain[-1]
                for node in self.neighbors.values():
                    self.block_send(self.blocks_all[last_block_private_chain_hash], node)
                self.blockchain_leafs[-1] = last_block_private_chain_hash
            elif deltaPrivatePublic == 2:  # After receiving the block, there is transition from lead of 2 to 0
                '''
                Honest miners close down the attacker's lead to 1, so if the attacker is selfish, it will
                publish the entire private chain. If the attacker is stubborn, it will reveal only the next
                block on it's private chain only to match the length of the public chain.
                '''
                # TODO: Can create a new data member for the class "Node" which denotes
                #       the attackers type. This can allow us to simulate multiple types
                #       of attackers at the same time.
                attacker_node_type = self.simulator.simulator_parameters.attacker_node_type

                if attacker_node_type == 'selfish':
                    for private_blk_hash in self.private_chain:
                        private_blk = self.blocks_all[private_blk_hash]
                        for node in self.neighbors.values():
                            self.block_send(private_blk, node)
                    self.blockchain_leafs[-1] = self.private_chain[-1]
                    self.private_chain.clear()
                elif attacker_node_type == 'stubborn':
                    first_unpublished_block_private_chain = self.private_chain[0]
                    for node in self.neighbors.values():
                        self.block_send(self.blocks_all[first_unpublished_block_private_chain], node)
                    self.blockchain_leafs[-1] = first_unpublished_block_private_chain
                    self.private_chain = self.private_chain[1:]
                else:
                    g_logger.error(f'FIXME: Invalid attacker node type encountered!')
            elif len(self.private_chain) > 0:  # After receiving the block, there is transition from lead of >=3 to >=2
                # The attacker's lead is above 2, so attacker will broadcast
                # the first unpublished block in it's private chain
                first_unpublished_block_private_chain = self.private_chain[0]
                for node in self.neighbors.values():
                    self.block_send(self.blocks_all[first_unpublished_block_private_chain], node)
                self.blockchain_leafs[-1] = first_unpublished_block_private_chain
                self.private_chain = self.private_chain[1:]

        if to_start_new_mining:
            # if block_obj.curr_block_hash not in self.blockchain_leafs:
            #     g_logger.error('Problem: Latest tail not properly working')
            self.mining_start()
        pass

    def get_new_transaction_greedy(self, curr_tail: str) -> List[Transaction]:
        # NOTE: python indexing [:N] automatically handles the case where length is less than "N"
        # NOTE: we do "self.max_transactions_per_block - 1" because first transaction is Mining Reward Transaction
        self.cache_update(curr_tail)
        txn_list: List[Transaction] = list()
        senders_balance: Dict[int, float] = defaultdict(float)
        for txn in self.txn_pool:
            senders_curr_balance: float = senders_balance[txn.id_sender] + self.cache_balance[curr_tail][txn.id_sender]
            # if self.is_transaction_valid(txn, curr_tail, senders_balance[txn.id_sender]):
            if txn.coin_amount <= senders_curr_balance or math.isclose(txn.coin_amount, senders_curr_balance):
                txn_list.append(txn)
                senders_balance[txn.id_sender] -= txn.coin_amount
                senders_balance[txn.id_receiver] += txn.coin_amount
        return copy.deepcopy(txn_list[:self.max_transactions_per_block - 1])
        # self.txn_pool = list(filter(lambda x: self.is_transaction_valid(x, curr_tail), self.txn_pool))
        # return copy.deepcopy(
        #     self.txn_pool[:self.max_transactions_per_block - 1]
        # )

    def get_new_block(self) -> Tuple[bool, Union[Block, None]]:
        # Point 7 of Assignment-1 PDF
        curr_tail = self.blockchain_leafs[-1]

        # If the private chain is empty, the attacker will mine on the latest block of the longest
        # public chain. Otherwise, it will mine on the latest block of it's private chain
        if self.is_attacker and len(self.private_chain) > 0:
            curr_tail = self.private_chain[-1]

        sp: SimulatorParameters = self.simulator.simulator_parameters
        txn_mining_reward: Union[Transaction, None] = None
        try:
            txn_mining_reward: Transaction = Transaction(
                self.simulator.get_global_time(),
                -1,
                self.node_id,
                sp.mining_reward_start * (
                        (1 + (sp.mining_reward_update_percent / 100)) **
                        ((self.blocks_all[curr_tail].index + 1) // sp.mining_reward_update_block_time)
                )
            )
        except Exception as e:
            g_logger.error(e)
            g_logger.debug(f'curr_tail       = {type(curr_tail)} {curr_tail}')
            g_logger.debug(
                f'self.blocks_all = {type(self.blocks_all)}, '
                f'{[[str(i), j.str_all()] for i, j in self.blocks_all.items()]}'
            )
            g_logger.error(traceback.format_exc())
            sys.exit(1)
        transactions_to_include = [txn_mining_reward] + self.get_new_transaction_greedy(curr_tail)

        block_mine_recv_time: float = self.simulator.get_global_time() \
                                      + numpy.random.exponential(self.T_k_exp_block_mining_mean)

        return True, Block(
            curr_tail,
            self.simulator.get_global_time(),
            self.blocks_all[curr_tail].index + 1,
            transactions_to_include,
            block_mine_recv_time,
            block_mine_recv_time
        )

    def mining_start(self) -> bool:
        new_block_status, new_block = self.get_new_block()
        if new_block_status == True and self.is_block_valid(new_block) == False:
            g_logger.error(f'Problem: FIXME: The block I created is invalid :(')

        if self.is_infected:
            if new_block_status == False:
                new_block_status = True
                block_mine_recv_time: float = self.simulator.get_global_time() \
                                              + numpy.random.exponential(self.T_k_exp_block_mining_mean)
                new_block = Block(
                    self.blockchain_leafs[-1],
                    self.simulator.get_global_time(),
                    self.blocks_all[self.blockchain_leafs[-1]].index + 1,
                    [Transaction(self.simulator.get_global_time(), -1, self.node_id, 1000)],
                    block_mine_recv_time,
                    block_mine_recv_time
                )
            new_block.transactions[0].coin_amount = 1000.0  # Changing mining reward amount
        if new_block_status == False:
            return False
        self.simulator.event_queue.push(
            Event(
                new_block.recv_time,
                EventType.EVENT_BLOCK_CREATE_SUCCESS,
                self.node_id,
                self.node_id,
                new_block
            )
        )

        self.block_generation_count += 1

        return True

    def mining_complete(self, block: Block) -> None:
        global g_logger
        # A "Block" which created new longest blockchain was received after the
        # mining started. Hence, we discard this mining complete request because
        # in real life this mining work is to be discarded.
        if not self.is_attacker:  # Honest Node
            if block.creation_time < self.last_receive_time:
                # This mining result is to be discarded because we received a new block which makes
                # a longer blockchain after the mining started and before it ended.
                g_logger.info(
                    f'Node Id = {self.node_id}, Mining start time = {block.creation_time:0.5f}, '
                    f'Block receive time = {self.last_receive_time:0.5f}, Current time = {self.simulator.get_global_time()}'
                )
                self.block_generation_count -= 1
                return

            # NOTE: the below two "IF" condition will never be True if `mining_start()` and its depends work correctly
            if self.blocks_all[self.blockchain_leafs[-1]].index > block.index:
                g_logger.warning(
                    f'Problem: node_id={self.node_id}, Block mining complete but a chain '
                    f'with longer length is present in "self.blockchain_leafs"'
                )
                g_logger.warning(f'Problem: node_id={self.node_id}, '
                                 f'len queue = {self.blocks_all[self.blockchain_leafs[-1]].index=}, '
                                 f'len mined = {self.blocks_all[block.curr_block_hash].index=}')
            if self.blockchain_leafs[-1] != block.prev_block_hash:
                g_logger.warning(f'Problem: node_id={self.node_id}, '
                                 f'len queue = {self.blocks_all[self.blockchain_leafs[-1]].index=}, '
                                 f'len mined = {self.blocks_all[block.curr_block_hash].index=}')
        else:  # The attacker node is not concerned about the public blockchain until the time is right
            if block.creation_time < self.last_change_branch_time:
                g_logger.info(
                    f'Node Id = {self.node_id}, Mining start time = {block.creation_time:0.5f}, '
                    f'Block receive time = {self.last_receive_time:0.5f}, Current time = {self.simulator.get_global_time()}'
                )
                self.block_generation_count -= 1
                return

            deltaPrivatePublic = 0
            if len(self.private_chain) > 0:
                deltaPrivatePublic = self.blocks_all[self.private_chain[-1]].index - \
                                     self.blocks_all[self.blockchain_leafs[-1]].index
            if deltaPrivatePublic >= 0:
                # Appending new block to the private chain
                self.private_chain.append(block.curr_block_hash)

        # Add block to the blockchain
        self.blocks_all[block.curr_block_hash] = block

        # Honest nodes will add the block to the public chain
        if not self.is_attacker:
            self.blockchain_leafs[-1] = block.curr_block_hash
        else:
            attacker_node_type = self.simulator.simulator_parameters.attacker_node_type

            if deltaPrivatePublic == 0 and len(self.private_chain) == 2 and attacker_node_type == "selfish":
                # This means that previously both the public and private chains were tied with
                # length 1 and attacker node is able to find another block, so it broadcasts all
                # the blocks in it's private chain
                for private_blk_hash in self.private_chain:
                    private_blk = self.blocks_all[private_blk_hash]
                    for node in self.neighbors.values():
                        self.block_send(private_blk, node)
                # Reset the private chain to empty list
                self.blockchain_leafs[-1] = self.private_chain[-1]
                self.private_chain.clear()

        # Remove processed transactions from the transaction pool
        # NOTE: we use [1:] because mining reward transaction will not be in the "self.txn_pool"
        for txn in block.transactions[1:]:
            try:
                self.txn_pool.remove(txn)
            except Exception as e:
                g_logger.error(e)
                g_logger.debug(f'txn                = {str(txn)}')
                g_logger.debug(f'block.transactions = {[str(i) for i in block.transactions]}')
                g_logger.debug(f'self.txn_pool      = {[str(i) for i in self.txn_pool]}')
                g_logger.error(traceback.format_exc())
                sys.exit(1)

        # Honest nodes will always broadcast the "block" to all of it's "self.neighbors"
        if not self.is_attacker:
            for node in self.neighbors.values():
                self.block_send(block, node)

        # Start mining a new block
        self.mining_start()

    def serialize_blockchain_to_str_v1(self) -> str:
        # TODO: update this if required
        return '\n'.join([block.str_all() for block in self.blocks_all.values()])

    def serialize_blockchain_to_str_v2(self) -> str:
        # Based on what was suggested on MSTeams
        # - Parameters to write: BlockHash, BlockNum, TimeOfArrival, ParentBlockHash
        # - Sorted based on block index
        all_blocks = sorted(list(self.blocks_all.values()), key=lambda x: x.index)
        return '\n'.join([
            f'{b.curr_block_hash},{b.index},{b.recv_time:.15f},{b.prev_block_hash}'
            for b in all_blocks
        ])


# REFER: https://www.tutorialspoint.com/enum-in-python
class EventType(enum.Enum):
    EVENT_UNDEFINED = 0
    EVENT_TRANSACTION_CREATE = 1  # Queue -> data_obj: Transaction
    EVENT_SEND_TRANSACTION = 2
    EVENT_RECV_TRANSACTION = 3  # Queue -> data_obj: Transaction
    EVENT_SEND_BLOCK = 4
    EVENT_RECV_BLOCK = 5  # Queue -> data_obj: Block
    EVENT_BLOCK_CREATE = 6
    EVENT_BLOCK_CREATE_SUCCESS = 7  # Queue -> data_obj: Block


class Event:
    def __init__(
            self,
            event_completion_time: float,
            event_type: EventType,
            event_creator_id: int,
            event_receiver_id: int,
            data_obj: Union[None, Transaction, Block]
    ):
        self.event_completion_time: float = event_completion_time
        self.event_type: EventType = event_type
        self.event_creator_id: int = event_creator_id
        self.event_receiver_id: int = event_receiver_id
        self.data_obj = data_obj

    def __str__(self) -> str:
        return f'Event({self.event_type.name}, {self.event_completion_time:.2f}, ' \
               f'{self.event_creator_id: 2d}, {self.event_receiver_id: 2d}, {self.data_obj})'

    def __lt__(self, other) -> bool:
        return type(self) == type(other) and self.event_completion_time < other.event_completion_time

    def str_all(self) -> str:
        if type(self.data_obj) == Block:
            res = f'Event({self.event_type.name}, {self.event_completion_time:.2f}, ' \
                  f'{self.event_creator_id: 2d}, {self.event_receiver_id: 2d}, Block('
            block_str = str([self.data_obj.prev_block_hash, self.data_obj.creation_time,
                             self.data_obj.index, len(self.data_obj.transactions)])
            return res + block_str + '))'
        else:
            return f'Event({self.event_type.name}, {self.event_completion_time:.2f}, ' \
                   f'{self.event_creator_id: 2d}, {self.event_receiver_id: 2d}, {self.data_obj})'


# REFER: https://docs.python.org/3/library/heapq.html
# REFER: https://www.geeksforgeeks.org/heap-queue-or-heapq-in-python/
class EventQueue:
    def __init__(self):
        # Tuple -> EventCompletionTime, Event
        self.events: List[Tuple[float, Event]] = list()
        self.add_new_events: bool = True

    def push(self, new_event: Event) -> None:
        if self.add_new_events == False:
            return
        heapq.heappush(self.events, (new_event.event_completion_time, new_event))

    def pop(self) -> Event:
        return heapq.heappop(self.events)[1]

    def top(self) -> Event:
        return self.events[0][1]

    def empty(self) -> bool:
        return len(self.events) == 0

    def freeze(self) -> None:
        self.add_new_events = False


def plot_graph_build(blocks_iter: Iterable[Block], blocks_leafs: List[str] = None) -> Digraph:
    # REFER: http://magjac.com/graphviz-visual-editor/
    #       - Playground for testing and immediate results
    # REFER: https://www.graphviz.org/pdf/dotguide.pdf (Found this from google of "dot language examples")
    #       - Main doc
    # REFER: https://stackoverflow.com/questions/49139028/change-subgraph-cluster-shape-to-rounded-rectangle
    #       - Rounded rectangle
    # REFER: https://graphviz.org/doc/info/shapes.html#record
    #       - Content inside a node
    # REFER: https://ant.design/docs/spec/colors
    #       - Colors
    if blocks_leafs is not None:
        g_logger.debug(f'Tail Count = {len(blocks_leafs)}')

    block_point_count: Dict[str, int] = defaultdict(int)
    for block in blocks_iter:
        block_point_count[block.prev_block_hash] += 1

    g = Digraph('blockchain', node_attr={'shape': 'record', 'style': 'rounded,filled', 'fontname': 'Arial'})
    g.graph_attr['rankdir'] = 'RL'

    for block in blocks_iter:
        point_count = block_point_count[block.curr_block_hash]
        # REFER: https://stackoverflow.com/questions/5466451/how-can-i-print-literal-curly-brace-characters-in-a-string-and-also-use-format
        miner_id: str = '?'
        if len(block.transactions) > 0 and block.transactions[0].id_sender == (-1):
            miner_id = str(block.transactions[0].id_receiver)
        block_label = f'<hash> Hash={block.curr_block_hash[:7]} ' \
                      f'|<link> Link={block.prev_block_hash[:7]} ' \
                      f'| MineTime={block.mine_time:.1f}' \
                      f'| {{Idx={block.index} | Miner={miner_id}}}' \
                      f'| {{NewTxnIncluded={len(block.transactions) - (miner_id != "?")}}}'
        # The below statement is used to check if we have any block hashes which are
        # not leaf blocks but their hashes are present in the leaf blocks list
        if blocks_leafs is not None and block.curr_block_hash in blocks_leafs:
            g_logger.debug(f'{block.curr_block_hash=} , {block.prev_block_hash=} , {point_count=}')
        if block.prev_block_hash == '-1':  # it is genesis block, color=light blue
            g.node(name=block.curr_block_hash, label=block_label, _attributes={'fillcolor': '#40a9ff'})
        elif point_count == 0:  # leaf node, color=light grey
            g.node(name=block.curr_block_hash, label=block_label, _attributes={'fillcolor': '#d9d9d9'})
        elif point_count == 1:  # color=light orange/yellow
            g.node(name=block.curr_block_hash, label=block_label, _attributes={'fillcolor': '#ffd591'})
        else:  # point_count >= 2, branching happens, color=light red
            g.node(name=block.curr_block_hash, label=block_label, _attributes={'fillcolor': '#ff4d4f'})
    for block in blocks_iter:
        if block.prev_block_hash == '-1':
            continue  # do NOTHING for genesis block
        # g.edge(tail_name=f'{block.curr_block_hash}:link',
        #        head_name=f'{block.prev_block_hash}:hash',
        #        _attributes={'weight': '0'})
        g.edge(tail_name=f'{block.curr_block_hash}', head_name=f'{block.prev_block_hash}')
    return g


def plot_graph_combo(nodes_list: List[Node], save_to_file: bool, base_path: str, file_name: str = ''):
    local_blocks_all: Set[Block] = set()
    for node in nodes_list:
        local_blocks_all = local_blocks_all.union(set(node.blocks_all.values()))

    g = plot_graph_build(local_blocks_all, None)

    time.sleep(0.5)
    if file_name == '':
        file_name = f'graph_len{len(nodes_list)}_NodeIndex_{nodes_list[0].node_id:03d}_combo'
    if save_to_file:
        g.view(filename=file_name, directory=base_path)
        # g.view(filename=file_name + '.pdf', directory=base_path)
        # g.view(filename=file_name + '.png', directory=base_path)
    else:
        g.view(directory=base_path)

    time.sleep(0.5)
    g.render()


def plot_graph(node: Node, save_to_file: bool, base_path: str):
    g = plot_graph_build(node.blocks_all.values(), node.blockchain_leafs)

    time.sleep(0.5)
    if save_to_file:
        g.view(filename=os.path.join(base_path, f'graph_NodeIndex_{node.node_id:03d}'))
    else:
        g.view(directory=base_path)

    time.sleep(0.5)
    g.render()


def plot_graph_allone(nodes_list: List[Node], save_to_file: bool, base_path: str, file_name: str = ''):
    block_point_count: Dict[str, int] = defaultdict(int)
    for node in nodes_list:
        for block in node.blocks_all.values():
            block_point_count[str(node.node_id) + '_' + block.prev_block_hash] += 1

    g = Digraph('blockchain', node_attr={'shape': 'record', 'style': 'rounded,filled', 'fontname': 'Arial'})
    g.graph_attr['rankdir'] = 'RL'
    # REFER: https://graphviz.readthedocs.io/en/stable/examples.html
    with g.subgraph() as g_genesis:
        g_genesis.attr(rank='same')
        for node in nodes_list:
            for block in node.blocks_all.values():
                point_count = block_point_count[str(node.node_id) + '_' + block.curr_block_hash]
                miner_id: str = '?'
                if len(block.transactions) > 0 and block.transactions[0].id_sender == (-1):
                    miner_id = str(block.transactions[0].id_receiver)
                block_label = f'Node={node.node_id}' \
                              f'|<hash> Hash={block.curr_block_hash[:7]} ' \
                              f'|<link> Link={block.prev_block_hash[:7]} ' \
                              f'| MineTime={block.mine_time:.1f}' \
                              f'| {{Idx={block.index} | Miner={miner_id}}}' \
                              f'| {{NewTxnIncluded={len(block.transactions) - (miner_id != "?")}}}'
                # The below statement is used to check if we have any block hashes which are
                # not leaf blocks but their hashes are present in the leaf blocks list
                if node.blockchain_leafs is not None and block.curr_block_hash in node.blockchain_leafs:
                    g_logger.debug(f'{block.curr_block_hash=} , {block.prev_block_hash=} , {point_count=}')
                if block.prev_block_hash == '-1':  # it is genesis block, color=light blue
                    g_genesis.node(name=str(node.node_id) + '_' + block.curr_block_hash, label=block_label,
                                   _attributes={'fillcolor': '#40a9ff'})

    for node in nodes_list:
        for block in node.blocks_all.values():
            point_count = block_point_count[str(node.node_id) + '_' + block.curr_block_hash]
            miner_id: str = '?'
            if len(block.transactions) > 0 and block.transactions[0].id_sender == (-1):
                miner_id = str(block.transactions[0].id_receiver)
            block_label = f'Node={node.node_id}' \
                          f'|<hash> Hash={block.curr_block_hash[:7]} ' \
                          f'|<link> Link={block.prev_block_hash[:7]} ' \
                          f'| MineTime={block.mine_time:.1f}' \
                          f'| {{Idx={block.index} | Miner={miner_id}}}' \
                          f'| {{NewTxnIncluded={len(block.transactions) - (miner_id != "?")}}}'
            # The below statement is used to check if we have any block hashes which are
            # not leaf blocks but their hashes are present in the leaf blocks list
            if node.blockchain_leafs is not None and block.curr_block_hash in node.blockchain_leafs:
                g_logger.debug(f'{block.curr_block_hash=} , {block.prev_block_hash=} , {point_count=}')
            if block.prev_block_hash == '-1':  # it is genesis block, color=light blue
                # g_genesis.node(name=str(node.node_id) + '_' + block.curr_block_hash, label=block_label,
                #        _attributes={'fillcolor': '#40a9ff'})
                pass
            elif point_count == 0:  # leaf node, color=light grey
                g.node(name=str(node.node_id) + '_' + block.curr_block_hash, label=block_label,
                       _attributes={'fillcolor': '#d9d9d9'})
            elif point_count == 1:  # color=light orange/yellow
                g.node(name=str(node.node_id) + '_' + block.curr_block_hash, label=block_label,
                       _attributes={'fillcolor': '#ffd591'})
            else:  # point_count >= 2, branching happens, color=light red
                g.node(name=str(node.node_id) + '_' + block.curr_block_hash, label=block_label,
                       _attributes={'fillcolor': '#ff4d4f'})
    for node in nodes_list:
        for block in node.blocks_all.values():
            if block.prev_block_hash == '-1':
                continue  # do NOTHING for genesis block
            # g.edge(tail_name=f'{block.curr_block_hash}:link',
            #        head_name=f'{block.prev_block_hash}:hash',
            #        _attributes={'weight': '0'})
            g.edge(tail_name=f'{node.node_id}_{block.curr_block_hash}',
                   head_name=f'{node.node_id}_{block.prev_block_hash}')

    if file_name == '':
        file_name = f'graph_len{len(nodes_list)}_NodeIndex_{nodes_list[0].node_id:03d}_allone'

    time.sleep(0.5)
    if save_to_file:
        g.view(filename=file_name, directory=base_path)
        # g.view(filename=file_name + '.pdf', directory=base_path)
        # g.view(filename=file_name + '.png', directory=base_path)
    else:
        g.view(directory=base_path)

    time.sleep(0.5)
    g.render()


def simulator_visualization(mySimulator: Simulator) -> None:
    try:
        print(f'\nAttacker Node Idx = {[node.node_id for node in mySimulator.nodes_list if node.is_attacker]}')
        print(f'\nInfected Node Idx = {[node.node_id for node in mySimulator.nodes_list if node.is_infected]}')
        print('\nEnter the input to VIEW/STORE (0/1) and (IndexN/all/allone/combo) '
              'of node of the graph on the same line')
        print('Input format: ^$ , 0 N , 1 (N|all|allone|combo)')
        print('Enter blank line to exit this')
        while view_options := input('Enter: ').split():
            # print(view_options)
            # This is not needed because bool value of empty list if False
            # if len(view_options) == 0:
            #     break
            if len(view_options) == 2:
                if view_options[1] == 'combo':
                    plot_graph_combo(
                        mySimulator.nodes_list,
                        view_options[0] == '1',
                        mySimulator.simulator_parameters.output_path,
                    )
                elif view_options[1] == 'allone':
                    plot_graph_allone(
                        mySimulator.nodes_list,
                        view_options[0] == '1',
                        mySimulator.simulator_parameters.output_path,
                    )
                elif view_options[1] == 'all':
                    if view_options[0] == 0:
                        view_options[0] = '1'
                        g_logger.warning('Saving blockchain tree for all nodes because "all" parameter was passed')
                    for i in mySimulator.nodes_list:
                        plot_graph(i, view_options[0] == '1', mySimulator.simulator_parameters.output_path)
                else:
                    try:
                        if int(view_options[1]) >= mySimulator.simulator_parameters.n_total_nodes:
                            g_logger.warning(
                                f'Total Nodes in the network = {mySimulator.simulator_parameters.n_total_nodes}'
                            )
                            continue
                        plot_graph(mySimulator.nodes_list[int(view_options[1])], view_options[0] == '1',
                                   mySimulator.simulator_parameters.output_path)
                    except Exception as e:
                        g_logger.error(e)
                        g_logger.error(traceback.format_exc())
            else:
                g_logger.warning('Invalid input')
    except Exception as e:
        # REFER: https://stackoverflow.com/questions/3702675/how-to-catch-and-print-the-full-exception-traceback-without-halting-exiting-the
        g_logger.error(e)
        g_logger.error(traceback.format_exc())
    pass


def simulation_analysis(mySimulator: Simulator) -> None:
    """This function is used to analyze the simulation results"""
    hash_power_median = numpy.median([
        node.node_hash_power_percent for node in mySimulator.nodes_list if not node.is_attacker
    ])

    # NOTE: we do not add 1 in the numerator because the genesis block is not mined by any miner
    network_longest_blockchain_length: int = max([
        node.blocks_all[node.blockchain_leafs[-1]].index for node in mySimulator.nodes_list
    ])

    # Ratio 1,2,4
    node_ratios: List[Tuple[float, float, float]] = list()
    print('---Each Node Stats---')
    for node in mySimulator.nodes_list:
        print('\nNode id = {node.node_id}')
        # total_blocks = len(node.blocks_all)

        # Points to the last block of the longest blockchain known to "node.node_id"
        block = node.blocks_all[node.blockchain_leafs[-1]]

        # # Total blocks in the longest blockchain known to "node.node_id"
        # len_longest_chain = block.index + 1

        # Total blocks in the longest blockchain known to "node.node_id" which are mined by the node itself
        node_blocks_in_longest_chain = 0

        while block.index != 0:
            # First transaction of each block if Mining Reward transaction
            # where the receiver is the miner of the block
            if block.transactions[0].id_receiver == node.node_id:
                node_blocks_in_longest_chain += 1
            block = node.blocks_all[block.prev_block_hash]

        print(f'Node hashing power = {node.node_hash_power_percent:.2f} %')

        if node.is_attacker:
            print('Attacker', end=',')
        else:
            print('Honest__', end=',')

        if node.is_infected:
            print('___Infected', end=',')
        else:
            print('NotInfected', end=',')

        if node.is_network_fast:
            print('Node type = Fast', end=',')
        else:
            print('Node type = Slow', end=',')

        if node.node_hash_power_percent > hash_power_median:
            print('CPU Power = High', end=',')
        else:
            print('CPU Power = Low_', end=',')

        # Ratio 1:
        #   numerator   = number of blocks mined by the node in the Longest Chain known to itself
        #   denominator = total number of blocks the node mines at the end of the simulation
        ratio1_val = None
        if node_blocks_in_longest_chain == 0:
            ratio1_val = 0
        elif node.block_generation_count == 0:
            ratio1_val = float('inf')
        else:
            ratio1_val = node_blocks_in_longest_chain / node.block_generation_count
        print(f'Ratio 1 (node_blocks_in_longest_chain / node.block_generation_count) = '
              f'({node_blocks_in_longest_chain} / {node.block_generation_count}) = {ratio1_val}')
        # Ratio 2:
        #   numerator   = fraction of "number of blocks mined by the node in the longest blockchain" to
        #                             "length of the network longest blockchain"
        #   denominator = mining power of the node in range [0, 1] (not in percentage)
        ratio2_val = (node_blocks_in_longest_chain / network_longest_blockchain_length) \
                     / (node.node_hash_power_percent / 100)
        print(f'Ratio 2 (fraction of node_blocks_in_longest_chain / (node.node_hash_power_percent / 100)) = '
              f'{ratio2_val}')
        # Ratio 4:
        #   numerator   = number of blocks in main chain by the node
        #   denominator = total number of blocks in the network longest chain
        ratio4_val = node_blocks_in_longest_chain / network_longest_blockchain_length
        print(f'Ratio 4 (node_blocks_in_longest_chain / network_longest_blockchain_length) = {ratio4_val}')

        node_ratios.append((
            ratio1_val,
            ratio2_val,
            ratio4_val
        ))

    for node in mySimulator.nodes_list:
        if not node.is_attacker:
            continue
        print('\nNode id = {node.node_id}')
        # Points to the last block of the longest blockchain known to "node.node_id"
        block = node.blocks_all[node.blockchain_leafs[-1]]
        # Total blocks in the longest blockchain known to "node.node_id" which are mined by the node itself
        node_blocks_in_longest_chain = 0
        while block.index != 0:
            # First transaction of each block if Mining Reward transaction
            # where the receiver is the miner of the block
            if block.transactions[0].id_receiver == node.node_id:
                node_blocks_in_longest_chain += 1
            block = node.blocks_all[block.prev_block_hash]
        print(f'MiningPowerUtilization_node_adv = {node_blocks_in_longest_chain / node.block_generation_count}')

    print('\n---Each Node Stats Arrays---')
    print('\nHash Power of Each Node =', [node.node_hash_power_percent for node in mySimulator.nodes_list])
    print('\nRatio 1 (node_blocks_in_longest_chain / node.block_generation_count) =', [i[0] for i in node_ratios])
    print('\nRatio 2 (fraction of node_blocks_in_longest_chain / (node.node_hash_power_percent / 100)) =',
          [i[1] for i in node_ratios])
    print('\nRatio 4 (node_blocks_in_longest_chain / network_longest_blockchain_length) =',
          [i[2] for i in node_ratios])

    print('\n---Global Stats---')
    # Ratio 3:
    #   numerator   = number of blocks mined by the whole network that are in the main chain
    #   denominator = total number of blocks mined by the whole network
    network_total_blocks_mined: int = sum([
        node.block_generation_count for node in mySimulator.nodes_list
    ])
    print(f'MPU_node_overall = Ratio (blocks in longest chain / total blocks mined) = '
          f'{network_longest_blockchain_length} / {network_total_blocks_mined} = '
          f'{network_longest_blockchain_length / network_total_blocks_mined}')
    pass


def debug_stats(mySimulator: Simulator):
    g_logger = logging.getLogger(__name__)
    os.chdir('src')
    mySimulator = joblib.load('./blockchains/mySimulator.pkl')
    for node in mySimulator.nodes_list:
        print(node.blockchain_leafs, node.blocks_all[node.blockchain_leafs[-1]].index)
    for node in mySimulator.nodes_list:
        print(len(node.blocks_all))
    for node in mySimulator.nodes_list:
        print(node.blocks_all[node.blockchain_leafs[-1]].index)
    for node in mySimulator.nodes_list:
        max_block_idx = -1
        for block in node.blocks_all.values():
            max_block_idx = max(max_block_idx, block.index)
        print(f'{node.node_id} MAX block index = {max_block_idx}')


# REFER: https://www.geeksforgeeks.org/python-progressbar-in-gtk-3/
# REFER: https://zetcode.com/python/gtk/
class ProgressBarWindow(Gtk.Window):
    def __init__(self):
        gui_lock.acquire()
        Gtk.Window.__init__(self, title='Simulation Progress')
        self.set_border_width(10)

        vbox = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)
        self.add(vbox)

        self.label = Gtk.Label()
        self.label.set_text('Initializing...')
        self.label.set_width_chars(50)
        vbox.pack_start(self.label, True, True, 0)

        # Create a ProgressBar
        self.progressbar = Gtk.ProgressBar()
        self.progressbar.set_size_request(width=150, height=-1)
        # self.progressbar.set_text('Initializing...')
        # self.progressbar.set_show_text(True)
        vbox.pack_start(self.progressbar, True, True, 0)

        # Create CheckButton with labels "Show text",
        # "Activity mode", "Right to Left" respectively
        button = Gtk.CheckButton(label="Activity mode")
        button.connect("toggled", self.on_activity_mode_toggled)
        vbox.pack_start(button, True, True, 0)

        # REFER: https://docs.gtk.org/glib/func.timeout_add.html
        self.timeout_id = GLib.timeout_add(500, self.on_timeout, None)
        self.activity_mode = False
        self.progress_percent: float = 0.0
        self.progress_label: str = 'Initializing...'
        gui_lock.release()

    def on_activity_mode_toggled(self, button):
        self.activity_mode = button.get_active()
        if self.activity_mode:
            self.progressbar.pulse()
        else:
            self.progressbar.set_fraction(0.0)

    def on_timeout(self, user_data):
        """
        Update value on the progress bar
        """
        if self.activity_mode:
            self.progressbar.pulse()
        else:
            # new_value = self.progressbar.get_fraction() + 0.01
            new_value = self.progress_percent
            if new_value > 1:
                new_value = 1
            self.progressbar.set_fraction(new_value)
            self.label.set_text(self.progress_label)
        return True

    @staticmethod
    def start_progressbar(win: 'ProgressBarWindow'):
        gui_lock.acquire()
        win.connect("destroy", Gtk.main_quit)
        win.show_all()
        gui_lock.release()
        Gtk.main()


def seconds_to_minsec(t: float) -> str:
    t_min = int(t / 60)
    t_sec = int(t % 60)
    return f'{t_min:02d}:{t_sec:02d}'


def Main(args: Dict):
    global g_logger
    from threading import Thread

    # REFER: https://stackoverflow.com/questions/2905965/creating-threads-in-python
    # REFER: https://www.geeksforgeeks.org/start-and-stop-a-thread-in-python/
    win = ProgressBarWindow()
    thread = Thread(target=ProgressBarWindow.start_progressbar, args=(win,), daemon=True)
    thread.start()

    gui_lock.acquire()
    win.activity_mode = True
    win.progress_label = 'Initializing...'
    gui_lock.release()

    sp = SimulatorParameters()
    sp.load_from_file(args['config'])
    sp.log_parameters()
    mySimulator = Simulator(sp)
    mySimulator.initialize()

    gui_lock.acquire()
    win.activity_mode = False
    win.progress_label = 'Executing...'
    gui_lock.release()
    last_progress: float = 0.0
    update_progress_i: int = -1
    update_progress_every_n_events: int = 20
    start_time: float = time.time()  # Time in seconds
    while mySimulator.get_global_time() <= sp.execution_time:
        # g_logger.debug(f'{mySimulator.get_global_time()=}')
        update_progress_i = (update_progress_i + 1) % update_progress_every_n_events
        if update_progress_i == 0:
            gui_lock.acquire()
            win.progress_percent = mySimulator.get_global_time() / sp.execution_time
            if win.progress_percent - last_progress > 0.0001:  # 0.01 / 100
                last_progress = win.progress_percent
                win.progress_label = (f'Executing ({mySimulator.get_global_time():.1f} of {sp.execution_time}, '
                                      f'{seconds_to_minsec(time.time() - start_time)}<'
                                      f'{seconds_to_minsec((time.time() - start_time) / win.progress_percent)})')
            gui_lock.release()
        status = mySimulator.execute_next_event()
        if status == False:
            g_logger.info('No events present in the event queue. Exiting...')
            break
        # input()

    # Finish executing all events which were triggered till now
    mySimulator.freeze()
    g_logger.info('Everything freezed except network :)')
    g_logger.info(f'Global Time = {mySimulator.get_global_time()}')

    gui_lock.acquire()
    win.progress_label = 'Everything freezed except network...'
    gui_lock.release()
    while True:
        # g_logger.debug(f'{mySimulator.get_global_time()=}')
        status = mySimulator.execute_next_event()
        if status == False:
            g_logger.info('No events present in the event queue. Exiting...')
            break
        # input()
    gui_lock.acquire()
    win.progress_percent = 1.0

    win.progress_label = 'Saving results...'
    gui_lock.release()
    if sp.simulator_data_filename != '':
        g_logger.info(f'Saving all the progress of simulator to "{sp.simulator_data_filename}"')
        joblib.dump(mySimulator, os.path.join(sp.output_path, sp.simulator_data_filename), compress=2)
    mySimulator.write_all_node_tree_to_file()

    gui_lock.acquire()
    win.progress_label = 'Visualization in progress...'
    gui_lock.release()
    simulator_visualization(mySimulator)
    simulation_analysis(mySimulator)

    g_logger.info(f'Successfully completed executing the simulator for "{sp.execution_time}" seconds')

    gui_lock.acquire()
    win.progress_percent = 1.0
    win.progress_label = 'Completed :)'
    gui_lock.release()
    print('Please close the Progress Window')
    thread.join()


if __name__ == '__main__':
    import argparse

    my_parser = argparse.ArgumentParser(prog='simulator.py',
                                        description='Discrete Event Simulator for a P2P Cryptocurrency Network',
                                        epilog='Enjoy the program :)',
                                        prefix_chars='-',
                                        allow_abbrev=False,
                                        add_help=True)
    my_parser.version = '1.1'
    my_parser.add_argument('--version', action='version')
    my_parser.add_argument('-D',
                           '--debug',
                           action='store_true',
                           help='Print debug information')
    my_parser.add_argument('-c',
                           '--config',
                           action='store',
                           type=str,
                           help='Path to the config file',
                           required=True)

    # Execute the parse_args() method
    args: argparse.Namespace = my_parser.parse_args()

    # Initialize "g_logger"
    g_logger = logging.getLogger(__name__)
    # REFER: https://stackoverflow.com/questions/384076/how-can-i-color-python-logging-output
    #            - https://github.com/xolox/python-coloredlogs
    if args.debug:
        # g_logger.setLevel(logging.DEBUG)
        coloredlogs.install(fmt='%(levelname)-5s [%(lineno)4s]: %(message)s', level='DEBUG',
                            logger=g_logger)
    else:
        # g_logger.setLevel(logging.INFO)
        coloredlogs.install(fmt='%(levelname)-5s [%(lineno)4s]: %(message)s', level='INFO',
                            logger=g_logger)

    g_logger.debug('Debugging is ON')
    g_logger.debug(f'{args=}')
    # REFER: https://stackoverflow.com/questions/13176173/python-how-to-flush-the-log-django/13753911
    g_logger.handlers[0].flush()

    Main(vars(args))
